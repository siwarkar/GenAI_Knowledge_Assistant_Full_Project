# GenAI Knowledge Assistant (RAG-Based)
### Production-Ready Generative AI Application for Enterprise Knowledge Retrieval

---

## ğŸ“Œ Overview
The **GenAI Knowledge Assistant** is a **production-ready Retrieval-Augmented Generation (RAG) system** designed to help enterprises quickly extract accurate answers from internal documents such as policies, manuals, FAQs, and reports.

Unlike traditional keyword-based search, this system enables **natural language querying** over organizational knowledge while keeping responses **grounded in source documents**, significantly reducing time spent searching and interpreting information.

---

## ğŸ¯ Business Problem
In most organizations, critical knowledge is scattered across:
- PDF policy documents
- Internal manuals
- Knowledge base articles
- FAQs and text files

Employees often spend **10â€“15 minutes per query** manually:
- Searching documents
- Scanning multiple files
- Interpreting relevant sections

This results in:
- Productivity loss
- Inconsistent answers
- High dependency on subject-matter experts

---

## âœ… Solution
This project implements a **GenAI-powered Knowledge Assistant** that:

- Accepts **natural language questions**
- Retrieves **relevant document context** using vector search
- Generates **accurate, grounded answers** using an LLM
- Exposes functionality via a **REST API**
- Provides an easy-to-use **Streamlit UI**

---

## ğŸ“ˆ Measurable Impact
- â± **~60% reduction in document search time**
- ğŸ“‰ Reduced dependency on manual document review
- ğŸ§  Improved accuracy and consistency of responses
- ğŸ” Reusable architecture for multiple departments

---

## ğŸ§  Key Concepts Demonstrated
- Retrieval-Augmented Generation (RAG)
- Embedding-based semantic search
- Vector databases (FAISS)
- Prompt engineering for grounded responses
- Separation of backend (AI logic) and frontend (UI)
- Production-style API deployment

---

## ğŸ—ï¸ System Architecture
User (UI / API Client)
â†“
Streamlit UI
â†“
FastAPI Backend
â†“
Retriever (FAISS Vector DB)
â†“
Relevant Document Chunks
â†“
Prompt Template + Context
â†“
LLM (OpenAI API)
â†“
Final Grounded Answer

---

## ğŸ§° Technology Stack

### Programming & Data
- Python
- Pandas
- SQL (conceptual integration)
- DuckDB (optional analytics)

### Generative AI
- OpenAI API (LLMs)
- Prompt Engineering
- Embeddings
- Retrieval-Augmented Generation (RAG)

### Vector Database
- FAISS (local, scalable)

### Backend & APIs
- FastAPI
- REST architecture
- Environment-based configuration

### Frontend
- Streamlit (lightweight UI)

### Dev & Ops
- Virtual environments
- Modular code structure
- Deployment-ready design

---

## ğŸ“ Project Structure
genai-knowledge-assistant/
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ main.py # FastAPI backend entry point
â”‚
â”œâ”€â”€ ui/
â”‚ â””â”€â”€ app.py # Streamlit user interface
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py # Environment & configuration
â”‚ â”œâ”€â”€ loader.py # Document loading (PDF/TXT)
â”‚ â”œâ”€â”€ vector_store.py # FAISS vector database logic
â”‚ â””â”€â”€ rag_chain.py # RAG pipeline orchestration
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ ingest_documents.py # One-time document ingestion
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ documents/ # Input documents
â”‚
â”œâ”€â”€ embeddings/ # Persisted FAISS index
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

---

## â–¶ï¸ How It Works (Step-by-Step)

1. **Document Ingestion**
   - PDF and text documents are loaded
   - Documents are split into chunks
   - Embeddings are generated
   - Vectors are stored in FAISS

2. **Query Handling**
   - User submits a natural language question
   - Relevant chunks are retrieved via vector similarity
   - Retrieved context is injected into the LLM prompt

3. **Answer Generation**
   - LLM generates a response grounded in retrieved content
   - Answer is returned via API and displayed in UI

---

## ğŸš€ How to Run Locally

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
2ï¸âƒ£ Configure environment

Create .env file:
OPENAI_API_KEY=your_api_key_here
3ï¸âƒ£ Add documents

Place PDFs or text files in:
data/documents/ 
```

## ğŸ§ª Example Use Cases

â€œWhat does the leave policy say about carry-forward?â€

â€œSummarize the employee handbook.â€

â€œWhat are the escalation steps in the operations manual?â€

â€œList key compliance requirements from policy documents.â€

## ğŸ” Why RAG (Instead of Fine-Tuning)?

Faster to update documents

Lower operational cost

Reduced hallucination risk

Better compliance and traceability

## ğŸ”® Future Enhancements

Source citation display

Role-based access control

Agentic AI for multi-step workflows

Docker + cloud deployment

Monitoring and evaluation metrics

## ğŸ‘¤ Author

Swapnil Iwarkar
Applied AI & Data Scientist
LinkedIn: https://linkedin.com/in/swapnil-iwarkar66
